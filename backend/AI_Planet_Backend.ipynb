{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install fastapi uvicorn python-multipart langchain langchain-community pypdf sqlalchemy pydantic python-jose[cryptography] passlib[bcrypt] llama-index faiss-gpu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bK6qOS2PXPsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "!ngrok authtoken [ngrok-token]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SIy60ujYaz4",
        "outputId": "7569e8ce-9101-4fda-961f-8a6e8d3b5ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.2\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "from fastapi import FastAPI, File, UploadFile, HTTPException, Depends\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional, List\n",
        "from datetime import datetime\n",
        "import os\n",
        "import shutil\n",
        "from sqlalchemy import create_engine, Column, Integer, String, DateTime\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker, Session\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from google.oauth2 import service_account\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI(title=\"PDF Q&A API\")\n",
        "\n",
        "# Configure CORS\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Google Cloud credentials setup\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"YOUR_SERVICE_KEY.JSON\"\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    \"YOUR_SERVICE_KEY.JSON\"\n",
        ")\n",
        "vertexai.init(project=\"YOUR_GCP_PROJECT_ID\", location=\"asia-south1\", credentials=credentials)\n",
        "\n",
        "# Database setup\n",
        "SQLALCHEMY_DATABASE_URL = \"sqlite:///./pdf_qa.db\"\n",
        "engine = create_engine(SQLALCHEMY_DATABASE_URL)\n",
        "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
        "Base = declarative_base()\n",
        "\n",
        "# Database Models\n",
        "class Document(Base):\n",
        "    __tablename__ = \"documents\"\n",
        "\n",
        "    id = Column(Integer, primary_key=True, index=True)\n",
        "    filename = Column(String, unique=True, index=True)\n",
        "    upload_date = Column(DateTime, default=datetime.utcnow)\n",
        "    file_path = Column(String)\n",
        "    vector_store_path = Column(String)\n",
        "\n",
        "# Create database tables\n",
        "Base.metadata.create_all(bind=engine)\n",
        "\n",
        "# Dependency to get database session\n",
        "def get_db():\n",
        "    db = SessionLocal()\n",
        "    try:\n",
        "        yield db\n",
        "    finally:\n",
        "        db.close()\n",
        "\n",
        "# Pydantic models for request/response\n",
        "class QuestionRequest(BaseModel):\n",
        "    document_id: int\n",
        "    question: str\n",
        "\n",
        "class QuestionResponse(BaseModel):\n",
        "    answer: str\n",
        "    document_id: int\n",
        "    question: str\n",
        "\n",
        "# File handling functions\n",
        "def save_upload_file(upload_file: UploadFile, destination: str) -> str:\n",
        "    try:\n",
        "        with open(destination, \"wb\") as buffer:\n",
        "            shutil.copyfileobj(upload_file.file, buffer)\n",
        "    finally:\n",
        "        upload_file.file.close()\n",
        "    return destination\n",
        "\n",
        "def process_pdf(file_path: str, document_id: int):\n",
        "    # Load PDF\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split text into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "    )\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Create embeddings and vector store\n",
        "    embeddings = HuggingFaceEmbeddings()\n",
        "    vector_store = FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "    # Save vector store\n",
        "    vector_store_path = f\"vector_stores/document_{document_id}\"\n",
        "    os.makedirs(\"vector_stores\", exist_ok=True)\n",
        "    vector_store.save_local(vector_store_path)\n",
        "\n",
        "    return vector_store_path\n",
        "\n",
        "# API endpoints\n",
        "@app.post(\"/upload/\")\n",
        "async def upload_file(\n",
        "    file: UploadFile = File(...),\n",
        "    db: Session = Depends(get_db)\n",
        "):\n",
        "    if not file.filename.endswith('.pdf'):\n",
        "        raise HTTPException(status_code=400, detail=\"Only PDF files are allowed\")\n",
        "\n",
        "    # Create uploads directory if it doesn't exist\n",
        "    os.makedirs(\"uploads\", exist_ok=True)\n",
        "\n",
        "    # Save file\n",
        "    file_path = f\"uploads/{file.filename}\"\n",
        "    save_upload_file(file, file_path)\n",
        "\n",
        "    # Create document record\n",
        "    db_document = Document(\n",
        "        filename=file.filename,\n",
        "        file_path=file_path\n",
        "    )\n",
        "    db.add(db_document)\n",
        "    db.commit()\n",
        "    db.refresh(db_document)\n",
        "\n",
        "    # Process PDF and save vector store\n",
        "    try:\n",
        "        vector_store_path = process_pdf(file_path, db_document.id)\n",
        "        db_document.vector_store_path = vector_store_path\n",
        "        db.commit()\n",
        "    except Exception as e:\n",
        "        db.delete(db_document)\n",
        "        db.commit()\n",
        "        os.remove(file_path)\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing PDF: {str(e)}\")\n",
        "\n",
        "    return {\"document_id\": db_document.id, \"filename\": file.filename}\n",
        "\n",
        "@app.post(\"/question/\", response_model=QuestionResponse)\n",
        "async def ask_question(\n",
        "    question_request: QuestionRequest,\n",
        "    db: Session = Depends(get_db)\n",
        "):\n",
        "    # Get document\n",
        "    document = db.query(Document).filter(Document.id == question_request.document_id).first()\n",
        "    if not document:\n",
        "        raise HTTPException(status_code=404, detail=\"Document not found\")\n",
        "\n",
        "    try:\n",
        "        # Load vector store\n",
        "        embeddings = HuggingFaceEmbeddings()\n",
        "        vector_store = FAISS.load_local(document.vector_store_path, embeddings,\n",
        "            allow_dangerous_deserialization=True)\n",
        "\n",
        "        # Get relevant documents\n",
        "        docs = vector_store.similarity_search(question_request.question, k=6)\n",
        "\n",
        "        # Prepare text context from relevant documents\n",
        "        context = \" \".join(doc.page_content for doc in docs)\n",
        "\n",
        "        # Prepare input for Gemini\n",
        "        input_text = f\"\\nContext: {context}\\n\\nQuestion: {question_request.question}\\n\\nPlease provide a comprehensive 4-5 line answer based on the given context.\"\n",
        "\n",
        "        # Initialize Gemini model\n",
        "        model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
        "\n",
        "        # Generate response\n",
        "        response = model.generate_content(input_text)\n",
        "        answer = response.text.strip()\n",
        "\n",
        "        return QuestionResponse(\n",
        "            answer=answer,\n",
        "            document_id=question_request.document_id,\n",
        "            question=question_request.question,\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing question: {str(e)}\")\n",
        "\n",
        "@app.get(\"/documents/\")\n",
        "async def list_documents(db: Session = Depends(get_db)):\n",
        "    documents = db.query(Document).all()\n",
        "    return documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRfbDcyZXa7L",
        "outputId": "467b8b1c-bba9-4b6b-ad2b-9de8d4c6571b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR_HUGGING_FACE_API_TOKEN\""
      ],
      "metadata": {
        "id": "uvVlFUj7b0mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the server with ngrok\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "import os\n",
        "from threading import Thread\n",
        "\n",
        "# Enable nested asyncio support\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Start ngrok tunnel\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "\n",
        "# Run the FastAPI app\n",
        "os.system('python -m uvicorn main:app --host 0.0.0.0 --port 8000')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxAVARIpYIYW",
        "outputId": "a13e15ce-68c4-46e0-99c5-2035c67b5b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://b681-34-148-230-12.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}